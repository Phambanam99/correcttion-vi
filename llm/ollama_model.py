# -*- coding: utf-8 -*-
"""
Ollama Online Model for Vietnamese Text Correction
Calls external Ollama API service for text correction
Models are fetched dynamically from the API
"""

import requests
import re
from config import OLLAMA_API_URL, DEFAULT_OLLAMA_MODEL, MAX_NEW_TOKENS, TEMPERATURE
from llm.prompts import SYSTEM_PROMPT

print(f"ðŸŒ [Ollama] API URL: {OLLAMA_API_URL}")
print("=" * 50)

# Cache for available models
_cached_models = None


def fetch_available_models() -> list:
    """
    Fetch available models from Ollama API dynamically.
    Returns list of model names.
    """
    global _cached_models
    
    try:
        response = requests.get(f"{OLLAMA_API_URL}/api/tags", timeout=10)
        response.raise_for_status()
        data = response.json()
        
        models = []
        for model in data.get("models", []):
            name = model.get("name", "")
            if name:
                models.append(name)
        
        _cached_models = models
        print(f"ðŸŒ [Ollama] Fetched {len(models)} models: {models}")
        return models
        
    except requests.exceptions.RequestException as e:
        print(f"âš ï¸ [Ollama] Cannot fetch models: {e}")
        return _cached_models or []


def get_available_models() -> list:
    """Return available Ollama models (cached or fetch new)"""
    if _cached_models is None:
        return fetch_available_models()
    return _cached_models


def correct_text(text: str, model_key: str = None) -> tuple[str, str]:
    """
    Sá»­a lá»—i vÄƒn báº£n báº±ng Ollama API.
    Returns: (vÄƒn_báº£n_Ä‘Ã£_sá»­a, giáº£i_thÃ­ch)
    
    Args:
        text: VÄƒn báº£n cáº§n sá»­a
        model_key: TÃªn model (cÃ³ thá»ƒ lÃ  tÃªn Ä‘áº§y Ä‘á»§ tá»« API)
    """
    # Get model name - use directly if provided, otherwise use default
    if model_key is None:
        model_key = DEFAULT_OLLAMA_MODEL
    
    # Model name is used directly (fetched from API)
    model_name = model_key
    
    # Build prompt
    user_prompt = f"""Äoáº¡n vÄƒn gá»‘c:
{text}

Tráº£ lá»i theo format (CHá»ˆ 1 Láº¦N, KHÃ”NG láº·p láº¡i):
[VÄ‚N Báº¢N ÄÃƒ Sá»¬A]
(viáº¿t Ä‘oáº¡n vÄƒn Ä‘Ã£ sá»­a á»Ÿ Ä‘Ã¢y)

[GIáº¢I THÃCH]
(liá»‡t kÃª cÃ¡c thay Ä‘á»•i á»Ÿ Ä‘Ã¢y má»™t cÃ¡ch ngáº¯n gá»n nháº¥t)

Báº¯t Ä‘áº§u:
[VÄ‚N Báº¢N ÄÃƒ Sá»¬A]
"""
    
    # === LOG: Ollama Input ===
    print("\n" + "=" * 50)
    print(f"ðŸ“¥ [Ollama - {model_name}] INPUT:")
    print("-" * 50)
    print(text[:200] + "..." if len(text) > 200 else text)
    print("-" * 50)
    
    try:
        # Call Ollama API
        response = requests.post(
            f"{OLLAMA_API_URL}/api/chat",
            json={
                "model": model_name,
                "messages": [
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": user_prompt}
                ],
                "stream": False,
                "options": {
                    "temperature": TEMPERATURE,
                    "num_predict": MAX_NEW_TOKENS
                }
            },
            timeout=120  # 2 minute timeout
        )
        
        response.raise_for_status()
        data = response.json()
        
        # Extract result from response
        result = data.get("message", {}).get("content", "")
        
        if not result:
            print("âš ï¸ [Ollama] Empty response from API")
            return text, "KhÃ´ng nháº­n Ä‘Æ°á»£c pháº£n há»“i tá»« Ollama API"
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ [Ollama] API Error: {e}")
        return text, f"Lá»—i káº¿t ná»‘i Ollama API: {str(e)}"
    
    # Parse káº¿t quáº£ Ä‘á»ƒ tÃ¡ch vÄƒn báº£n vÃ  giáº£i thÃ­ch
    corrected_text = ""
    explanation = ""
    
    # TÃ¬m Táº¤T Cáº¢ cÃ¡c pháº§n [VÄ‚N Báº¢N ÄÃƒ Sá»¬A] vÃ  láº¥y pháº§n CUá»I CÃ™NG
    all_matches = list(re.finditer(
        r'\[VÄ‚N Báº¢N ÄÃƒ Sá»¬A\]\s*(.*?)(?=\[GIáº¢I TH[IÃá»Š][ÃŠáº¾á»†]?[CT]H?\]|\[VÄ‚N Báº¢N|```|$)', 
        result, re.DOTALL | re.IGNORECASE
    ))
    if all_matches:
        corrected_text = all_matches[-1].group(1).strip()
    else:
        parts = result.split("Äoáº¡n vÄƒn Ä‘Ã£ sá»­a:")
        if len(parts) > 1:
            corrected_text = parts[-1].strip()
        else:
            corrected_text = text  # Giá»¯ nguyÃªn náº¿u khÃ´ng parse Ä‘Æ°á»£c
    
    # TÃ¬m pháº§n [GIáº¢I THÃCH]
    explain_match = re.search(r'\[GIáº¢I TH[IÃá»Š][ÃŠáº¾á»†]?[CT]H?\]\s*(.*?)$', result, re.DOTALL | re.IGNORECASE)
    if explain_match:
        explanation = explain_match.group(1).strip()
    
    # LÃ m sáº¡ch vÄƒn báº£n
    corrected_text = re.sub(r'```.*?```', '', corrected_text, flags=re.DOTALL)
    corrected_text = re.sub(r'\[GIáº¢I TH.*', '', corrected_text, flags=re.DOTALL | re.IGNORECASE)
    corrected_text = corrected_text.strip('` \n\t')
    
    # === LOG: Ollama Output ===
    print(f"ðŸ“¤ [Ollama - {model_name}] OUTPUT:")
    print("-" * 50)
    print(f"VÄƒn báº£n: {corrected_text[:100]}...")
    print(f"Giáº£i thÃ­ch: {explanation[:100]}..." if explanation else "KhÃ´ng cÃ³ giáº£i thÃ­ch")
    print("=" * 50)

    return corrected_text, explanation


def check_ollama_health() -> bool:
    """Check if Ollama API is reachable"""
    try:
        response = requests.get(f"{OLLAMA_API_URL}/api/tags", timeout=5)
        return response.status_code == 200
    except:
        return False
